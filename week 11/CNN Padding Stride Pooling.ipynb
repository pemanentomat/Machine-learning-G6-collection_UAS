{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding and Stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source : https://d2l.ai/chapter_convolutional-neural-networks/padding-and-strides.html\n",
    "\n",
    "6.3.1. Padding\n",
    "\n",
    "In the following example, we create a two-dimensional convolutional layer with a height and width of 3 and apply 1 pixel of padding on all sides. Given an input with a height and width of 8, we find that the height and width of the output is also 8.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5VSuX7HAEwm",
    "outputId": "0cfe04e5-d3a4-4159-e909-609f60d6f4e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "# We define a convenience function to calculate the convolutional layer. This\n",
    "# function initializes the convolutional layer weights and performs\n",
    "# corresponding dimensionality elevations and reductions on the input and\n",
    "# output\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # Here (1, 1) indicates that the batch size and the number of channels\n",
    "    # are both 1\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    # Exclude the first two dimensions that do not interest us: examples and\n",
    "    # channels\n",
    "    return Y.reshape(Y.shape[2:])\n",
    "# Note that here 1 row or column is padded on either side, so a total of 2\n",
    "# rows or columns are added\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1)\n",
    "X = torch.rand(size=(8, 8))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDayTK6dAU0b"
   },
   "source": [
    "When the height and width of the convolution kernel are different, we can make the output and input have the same height and width by setting different padding numbers for height and width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aead-MnwAV20",
    "outputId": "d3706a9d-3577-4c2a-d641-834ad43f85c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, we use a convolution kernel with a height of 5 and a width of 3. The\n",
    "# padding numbers on either side of the height and width are 2 and 1,\n",
    "# respectively\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbRUWh_6AamE"
   },
   "source": [
    "6.3.2. Stride\n",
    "\n",
    "Below, we set the strides on both the height and width to 2, thus halving the input height and width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5LgPcj8YAkEV",
    "outputId": "a0473dfd-85a3-4565-da6f-2bfe6777e0a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ytls-dnnApZ8",
    "outputId": "e120dd4c-acde-4a0d-e78d-d4b3fe615636"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Next, we will look at a slightly more complicated example.\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9WxvvsnA9Rr"
   },
   "source": [
    "**6.3.3. Summary**\n",
    "\n",
    "1. Padding can increase the height and width of the output. This is often used to give the output the same height and width as the input.\n",
    "\n",
    "2. The stride can reduce the resolution of the output, for example reducing the height and width of the output to only  1/n  of the height and width of the input ( n  is an integer greater than  1 ).\n",
    "\n",
    "3. Padding and stride can be used to adjust the dimensionality of the data effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVg9QJXZBaM1"
   },
   "source": [
    "# 6.4. Multiple Input and Multiple Output Channels\n",
    "\n",
    "**6.4.1. Multiple Input Channel**s\n",
    "\n",
    "To make sure we really understand what is going on here, we can implement cross-correlation operations with multiple input channels ourselves. Notice that all we are doing is performing one cross-correlation operation per channel and then adding up the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9iMDEIcuBnvs"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l\n",
    "\n",
    "def corr2d_multi_in(X, K):\n",
    "    # First, iterate through the 0th dimension (channel dimension) of `X` and\n",
    "    # `K`. Then, add them together\n",
    "    return sum(d2l.corr2d(x, k) for x, k in zip(X, K))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsQLAhhLBsNr"
   },
   "source": [
    "We can construct the input tensor X and the kernel tensor K corresponding to the values in Fig. 6.4.1 to validate the output of the cross-correlation operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aDiVR4kYBs_j",
    "outputId": "1699084b-dbd0-4888-a3ae-035bca7cc8f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgX3dUKhBu0j"
   },
   "source": [
    "**6.4.2. Multiple Output Channels**\n",
    "\n",
    "We implement a cross-correlation function to calculate the output of multiple channels as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "f1bibPrkB58d"
   },
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # Iterate through the 0th dimension of `K`, and each time, perform\n",
    "    # cross-correlation operations with input `X`. All of the results are\n",
    "    # stacked together\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YiBTfecCBdV"
   },
   "source": [
    "We construct a convolution kernel with 3 output channels by concatenating the kernel tensor K with K+1 (plus one for each element in K) and K+2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNFH8OhlCCR8",
    "outputId": "6d486df9-15ae-4f23-9726-1fd474b79714"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.stack((K, K + 1, K + 2), 0)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tREyd2S4CF_j"
   },
   "source": [
    "Below, we perform cross-correlation operations on the input tensor X with the kernel tensor K. Now the output contains 3 channels. The result of the first channel is consistent with the result of the previous input tensor X and the multi-input channel, single-output channel kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LtKJr8KxCKAj",
    "outputId": "0414e127-1698-4b87-8f48-c726b4373323"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeT_RfyqCMtb"
   },
   "source": [
    "**6.4.3.  1×1  Convolutional Layer**\n",
    "\n",
    "Let us check whether this works in practice: we implement a  1×1  convolution using a fully-connected layer. The only thing is that we need to make some adjustments to the data shape before and after the matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zw2iEDGlCUNt"
   },
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape((c_i, h * w))\n",
    "    K = K.reshape((c_o, c_i))\n",
    "    # Matrix multiplication in the fully-connected layer\n",
    "    Y = torch.matmul(K, X)\n",
    "    return Y.reshape((c_o, h, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyUxwfswCWJd"
   },
   "source": [
    "When performing  1×1  convolution, the above function is equivalent to the previously implemented cross-correlation function corr2d_multi_in_out. Let us check this with some sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "y1KYCQoICYhk"
   },
   "outputs": [],
   "source": [
    "X = torch.normal(0, 1, (3, 3, 3))\n",
    "K = torch.normal(0, 1, (2, 3, 1, 1))\n",
    "\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "assert float(torch.abs(Y1 - Y2).sum()) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tm3bfNHqCaP0"
   },
   "source": [
    "**6.4.4. Summary**\n",
    "\n",
    "\n",
    "1. Multiple channels can be used to extend the model parameters of the convolutional layer.\n",
    "\n",
    "2. The  1×1  convolutional layer is equivalent to the fully-connected layer, when applied on a per pixel basis.\n",
    "\n",
    "3. The  1×1  convolutional layer is typically used to adjust the number of channels between network layers and to control model complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6acDS26C4fk"
   },
   "source": [
    "#6.5. Pooling\n",
    "\n",
    "**6.5.1. Maximum Pooling and Average Pooling**\n",
    "\n",
    "In the code below, we implement the forward propagation of the pooling layer in the pool2d function. This function is similar to the corr2d function in Section 6.2. However, here we have no kernel, computing the output as either the maximum or the average of each region in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Ou7bdXDjDDQW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hq7GGiKwDD3U"
   },
   "source": [
    "We can construct the input tensor X in Fig. 6.5.1 to validate the output of the two-dimensional maximum pooling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "owQCqZ9hDGWz",
    "outputId": "7a1081f9-9210-4d75-9947-a12a09c76bf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "pool2d(X, (2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ky5N0gIYDIfs"
   },
   "source": [
    "Also, we experiment with the average pooling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h9EVmEwlDMwr",
    "outputId": "ece40a45-b574-44d4-e0cd-faef5fd12226"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X, (2, 2), 'avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBJJyQrfDRdD"
   },
   "source": [
    "6.5.2. Padding and Stride\n",
    "\n",
    "As with convolutional layers, pooling layers can also change the output shape.And as before, we can alter the operation to achieve a desired output shape by padding the input and adjusting the stride. \n",
    "\n",
    "We can demonstrate the use of padding and strides in pooling layers via the built-in two-dimensional maximum pooling layer from the deep learning framework. \n",
    "\n",
    "We first construct an input tensor X whose shape has four dimensions, where the number of examples (batch size) and number of channels are both 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZlVc5WkDhvN",
    "outputId": "0dc09452-a2ce-49ab-cbca-e5dd1dcbe2f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WV3ry8N5DiWV"
   },
   "source": [
    "By default, the stride and the pooling window in the instance from the framework’s built-in class have the same shape. Below, we use a pooling window of shape (3, 3), so we get a stride shape of (3, 3) by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SEwrmeVIDk1V",
    "outputId": "b65d6d4b-64de-43eb-ee76-dba5f49da8ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[10.]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zUFJ217_Dpc7",
    "outputId": "a0e4d988-f777-4a02-a7df-7696d8025977"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The stride and padding can be manually specified.\n",
    "\n",
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XCiAt-OlDuYV",
    "outputId": "1f710ffe-9526-42ef-ab3c-cb36e592258f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Of course, we can specify an arbitrary rectangular pooling window and specify the padding and stride for height and width, respectively.\n",
    "\n",
    "pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1))\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdSeYfiZD2Fz"
   },
   "source": [
    "**6.5.3. Multiple Channels**\n",
    "\n",
    "When processing multi-channel input data, the pooling layer pools each input channel separately, rather than summing the inputs up over channels as in a convolutional layer. This means that the number of output channels for the pooling layer is the same as the number of input channels. \n",
    "\n",
    "Below, we will concatenate tensors X and X + 1 on the channel dimension to construct an input with 2 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GjSnnBb7D_BD",
    "outputId": "78d1bafa-aa5e-4674-a03a-f8155a5849f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]],\n",
       "\n",
       "         [[ 1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 9., 10., 11., 12.],\n",
       "          [13., 14., 15., 16.]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.cat((X, X + 1), 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZVzkMQMEAHE"
   },
   "source": [
    "As we can see, the number of output channels is still 2 after pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vG0D8EJlECt1",
    "outputId": "7049ef7d-ee7d-47a4-cd26-0a9d4dd156a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[ 6.,  8.],\n",
       "          [14., 16.]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTU-WhyFEEoD"
   },
   "source": [
    "**6.5.4. Summary**\n",
    "\n",
    "Taking the input elements in the pooling window, the maximum pooling operation assigns the maximum value as the output and the average pooling operation assigns the average value as the output.\n",
    "\n",
    "One of the major benefits of a pooling layer is to alleviate the excessive sensitivity of the convolutional layer to location.\n",
    "\n",
    "We can specify the padding and stride for the pooling layer.\n",
    "\n",
    "Maximum pooling, combined with a stride larger than 1 can be used to reduce the spatial dimensions (e.g., width and height).\n",
    "\n",
    "The pooling layer’s number of output channels is the same as the number of input channels.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6f86c6bc9c9469b2c84cfe0cb33110478d210a1f255f386dfb189826f594413"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('machinelearning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
